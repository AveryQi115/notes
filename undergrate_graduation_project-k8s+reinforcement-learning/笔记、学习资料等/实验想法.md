# 实验想法

## 建模

- state：N node N1 pod（实时查看） n 评估指标(cpu利用率，内存利用率) （异构：记录每个Node的剩余）（先做没有limit和request）

  - 资源考量：历史五分钟计算
  - 负载均衡考量：互补性

  （一台物理服务器是由多个NUMA做成的，NUMA：资源分块，CPU+附属内存）

- action：N个node cpu，mem + - cpu，mem（迁走pod的cpu，mem）

- reward：

  - 资源考量： 占用总node数    超出规定范围资源利用率（阈值-->引入超参，尽可能接近maxlimit，minlimit惩罚更大）的node的数量
  - 负载均衡考量：互补性差值（权重调低）
  - 性能考量：SLAV次数(规定application最大响应时间R_max)
  - k8s迁移成本：不要过多迁移（根据每个Pod的镜像大小）
  - 整理：weighted sum
  - 五个目标：通信量（x），活动服务器数量，能耗（x），集群负载均衡（资源相关性，cpu和mem都要同时尽可能的用满，违背这个指标可能出现单一指标优化好，其他指标有问题），服务质量，高可靠性和可用性 

## 下周目标

- 形式化建模（尝试）
- VMagent代码阅读



## 模型结合

- 1min预测一次，预测未来5min
- 动态部署：5min运行一次，用prediction模型计算出的预测值计算
- 动态部署state：实时查看state（基于统计的响应式的动态部署决策），未来预测state（基于预测的主动式动态部署决策）

k8s：

资源量变化(没有pod预设limit，request)-->迁移（RL_model）

scaling：

实时资源量变化---->有预设limit，request-->扩容--->迁移（kube）